{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': np.float64(0.001), 'eta0': np.float64(0.001), 'l1_ratio': np.float64(0.0), 'learning_rate': 'constant', 'loss': 'epsilon_insensitive', 'penalty': 'elasticnet'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.float64(0.044)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDRegressor  # Импортируем регрессор SGD\n",
    "from sklearn.model_selection import GridSearchCV  # Импортируем класс для поиска по сетке\n",
    "from sklearn.model_selection import train_test_split  # Импортируем функцию для разделения данных на обучающую и тестовую выборки\n",
    "from sklearn.metrics import mean_squared_error  # Импортируем функцию для вычисления среднеквадратичной ошибки\n",
    "import seaborn as sns  # Импортируем библиотеку Seaborn для визуализации данных\n",
    "import pandas as pd  # Импортируем библиотеку Pandas для работы с данными в формате DataFrame\n",
    "import numpy as np  # Импортируем библиотеку NumPy для работы с массивами\n",
    "\n",
    "# Загрузите стандартный датасет об алмазах из библиотеки Seaborn:\n",
    "df = sns.load_dataset('diamonds')  # Загружаем датасет о алмазах\n",
    "\n",
    "# Удалите часть признаков:\n",
    "df.drop(['depth', 'table', 'x', 'y', 'z'], axis=1, inplace=True)  # Удаляем ненужные признаки для упрощения модели\n",
    "\n",
    "# Закодируйте категориальные признаки:\n",
    "df = pd.get_dummies(df, drop_first=True)  # Преобразуем категориальные переменные в числовые с помощью one-hot кодирования, исключая первую категорию\n",
    "\n",
    "# Логарифмируйте признаки:\n",
    "df['carat'] = np.log(1 + df['carat'])  # Применяем логарифмическое преобразование к признаку 'carat'\n",
    "df['price'] = np.log(1 + df['price'])  # Применяем логарифмическое преобразование к целевой переменной 'price'\n",
    "\n",
    "# Определите целевую переменную и предикторы:\n",
    "X_cols = [col for col in df.columns if col != 'price']  # Создаем список признаков, исключая целевую переменную 'price'\n",
    "X = df[X_cols]  # Определяем матрицу предикторов\n",
    "# Как альтернатива отделения признаков\n",
    "# X = df.drop(columns=\"price\")  # Альтернативный способ определения предикторов, удаляя столбец 'price'\n",
    "y = df['price']  # Определяем целевую переменную\n",
    "\n",
    "# Разделяем данные на обучающую и тестовую выборки:\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)  \n",
    "# Разделяем данные на обучающую (67%) и тестовую (33%) выборки с фиксированным состоянием генератора случайных чисел\n",
    "\n",
    "# Определяем параметры для поиска по сетке:\n",
    "parameters = {\n",
    "    \"loss\": [\"squared_error\", \"epsilon_insensitive\"],  # Возможные функции потерь\n",
    "    \"penalty\": [\"elasticnet\"],  # Тип регуляризации\n",
    "    \"alpha\": np.logspace(-3, 3, 10),  # Значения параметра регуляризации alpha в логарифмическом масштабе\n",
    "    \"l1_ratio\": np.linspace(0, 1, 10),  # Соотношение L1 и L2 в регуляризации\n",
    "    \"learning_rate\": [\"constant\"],  # Фиксированная скорость обучения\n",
    "    \"eta0\": np.logspace(-4, -1, 4)   # Значения начальной скорости обучения eta0 в логарифмическом масштабе\n",
    "}\n",
    "\n",
    "sgd = SGDRegressor(random_state=42)  # Инициализируем регрессор SGD с фиксированным состоянием генератора случайных чисел\n",
    "sgd_cv = GridSearchCV(estimator=sgd, param_grid=parameters, n_jobs=-1)  \n",
    "# Инициализируем поиск по сетке с использованием SGDRegressor и заданными параметрами; n_jobs=-1 позволяет использовать все доступные ядра процессора\n",
    "\n",
    "sgd_cv.fit(X_train, y_train)  # Обучаем модель на обучающей выборке\n",
    "\n",
    "print(sgd_cv.best_params_)  # Выводим лучшие параметры модели после поиска по сетке\n",
    "\n",
    "sgd = SGDRegressor(**sgd_cv.best_params_, random_state=42)  \n",
    "# Инициализируем новый регрессор SGD с лучшими параметрами из поиска по сетке\n",
    "\n",
    "sgd.fit(X_train, y_train)  # Обучаем модель на обучающей выборке с лучшими параметрами\n",
    "sgd.score(X_train, y_train)  # Оцениваем модель на обучающей выборке (вычисляем коэффициент детерминации R^2)\n",
    "\n",
    "ls = sgd.predict(X_test)  # Предсказываем значения целевой переменной на тестовой выборке\n",
    "\n",
    "round(mean_squared_error(y_test, ls), 3)  # Вычисляем и округляем среднеквадратичную ошибку между предсказанными и истинными значениями на тестовой выборке"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
